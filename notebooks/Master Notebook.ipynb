{
 "metadata": {
  "name": "",
  "signature": "sha256:996bddb193e8d9a115535f8234d2c9d102411231438cf457b4d682a32a3dc97f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import sys\n",
      "import pickle\n",
      "import nltk\n",
      "import string\n",
      "import numpy as np\n",
      "import pandas\n",
      "import csv\n",
      "from nltk.corpus import wordnet as wn\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn import datasets, linear_model, metrics\n",
      "sys.path.append('../Scripts')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# loading data from pickle files (tokenization & tagging- default nltk)\n",
      "import ted_object\n",
      "from ted_object import ted\n",
      "t_obj = ted()\n",
      "\n",
      "# Corpus objects\n",
      "tagged_sents = t_obj.tagged_sents_talk()\n",
      "tagged_words = t_obj.tagged_words_talk()\n",
      "tagged_paras = t_obj.tagged_paras()\n",
      "#words_bag = t_obj.words_bag()\n",
      "\n",
      "# y labels\n",
      "all_labels = pickle.load(open('../Corpus/y.p', 'rb'))\n",
      "confusing_y = [row[0] for row in all_labels]\n",
      "funny_y = [row[1] for row in all_labels]\n",
      "informative_y = [row[2] for row in all_labels]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The history saving thread hit an unexpected error (OperationalError('disk I/O error',)).History will not be written to the database.\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Normalize text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords\n",
      "from nltk.stem import *\n",
      "from nltk.stem.porter import *\n",
      "\n",
      "def tokenize_text(text):\n",
      "    \"\"\"Retains '(laughs)'\"\"\"\n",
      "    pattern =[\"(?x)([A-Z]\\.)+\",\n",
      "               \"\\w+([-]\\w+)*\",\n",
      "               \"\\$?\\d+(\\.\\d+)?%?\",\n",
      "               \"\\.\\.\\.\",\n",
      "               \"[.,?;]+\"]\n",
      "    pattern = \"|\".join(pattern)\n",
      "    text = \" \".join(text) if isinstance(text, list) == True else text\n",
      "    tokens = nltk.regexp_tokenize(text,pattern)\n",
      "    return tokens\n",
      "\n",
      "wnl = WordNetLemmatizer()\n",
      "\n",
      "# reduce words to root format\n",
      "def get_root_phrase(word, tag):\n",
      "    word = word.lower()\n",
      "    #trim joint words\n",
      "    if word.endswith(\"'s\"):\n",
      "        print word\n",
      "        word = word[:-2]\n",
      "    #don't cut short words. e.g. rss would be reduced to r\n",
      "    if len(word)<=3 and word not in COMMON_WORDS:\n",
      "        return word\n",
      "    #try to morphy\n",
      "    morphy = wn.morphy(word)\n",
      "    if morphy is None:\n",
      "        morphy = word\n",
      "    #lemmatize morphy\n",
      "    lem = wnl.lemmatize(morphy, 'n')\n",
      "    if lem and len(word)>3: \n",
      "        morphy = lem\n",
      "    return morphy\n",
      "\n",
      "# Get morphy words in a sentence\n",
      "def get_morphys(tagged_sentence):\n",
      "   return [ (get_root_phrase(word, tag), tag) for (word, tag) in tagged_sentence \\\n",
      "               if word not in stop_words and (word.isalnum() or '-' in word) and not word.isdigit()\\\n",
      "               and len(get_root_phrase(word, tag))>1]\n",
      "\n",
      "#remove all stop words and punctuations\n",
      "non_stop_words = list()\n",
      "for talk in tagged_words:\n",
      "    non_stop_words.append([(w,t) for w,t in talk if w.lower() not in stopwords.words('english') and\n",
      "                       w.lower() not in string.punctuation])\n",
      "pickle.dump(non_stop_words, open( \"../Corpus/non_stop_tagged_words_talks.p\", \"wb\" ))\n",
      "\n",
      "porter_stemmer = PorterStemmer()\n",
      "stemmed_words = list()\n",
      "for talk in non_stop_words:\n",
      "    stemmed_words.append([(porter_stemmer.stem(w),t) for w,t in talk])\n",
      "pickle.dump(stemmed_words, open( \"../Corpus/stemmed_tagged_words_talks.p\", \"wb\" ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-7-5fb507bb2857>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mnon_stop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtalk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtagged_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     non_stop_words.append([(w,t) for w,t in talk if w.lower() not in stopwords.words('english') and\n\u001b[0m\u001b[0;32m     47\u001b[0m                        w.lower() not in string.punctuation])\n\u001b[0;32m     48\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_stop_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"../Corpus/non_stop_tagged_words_talks.p\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\sjeyabal\\Anaconda\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.pyc\u001b[0m in \u001b[0;36mwords\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \"\"\"\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\sjeyabal\\Anaconda\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.pyc\u001b[0m in \u001b[0;36mraw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fileids\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Helper functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#helper function to chunk the sentenses based on a grammar\n",
      "def parse_sents(ip_sent, grammar):\n",
      "    cp = nltk.RegexpParser(grammar)\n",
      "    result = cp.parse(ip_sent)\n",
      "    return result\n",
      "\n",
      "#helper function to extract subtrees\n",
      "def extract_tree(sents,grammar, match):\n",
      "    ret_list = []\n",
      "    for sent in sents:\n",
      "        res = parse_sents(sent, grammar)\n",
      "        ret_list += [' '.join([word for(word, tag) in subtree]) for subtree in res.subtrees(filter = lambda t: t.node == match)]\n",
      "    return ret_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Feature Extraction Functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NEGATION_LIST = [\"no\", \"not\", \"never\", \"can't\", \"won't\"]\n",
      "CERTAINTY_LIST = [\"always\", \"never\", \"often\", \"sometimes\"]\n",
      "HEDGE_LIST = [\"well\", \"possibly\", \"maybe\"]\n",
      "\n",
      "def min_max_normalize(feature):\n",
      "    '''Converts a list of numberical values to a list of values between 0 and 1'''\n",
      "    minVal = min(feature)\n",
      "    maxVal = max(feature)\n",
      "    normalized = [(e - minVal / (maxVal - minVal + 1) ) for e in feature] #Adding 1 as a stop gap measure\n",
      "    return normalized\n",
      "\n",
      "\n",
      "def punctuation_count(talk_sents, punc):\n",
      "    featureVector = []\n",
      "    for talk in talk_sents:\n",
      "        num_punc = len([1 for sent in talk for w,t in sent if punc == w])\n",
      "        featureVector.append(num_punc)\n",
      "    return featureVector\n",
      "\n",
      "# From the paper Rahul mentioned for Technical terms - Citation required\n",
      "def num_techterms(talk_sents):\n",
      "    featureVector = []\n",
      "    for talk in talk_sents:\n",
      "        njn_list = extract_tree(talk, 'NJN: {(<N.*>*<J*>*<N.*>+)+}','NJN')\n",
      "        npn_list = extract_tree(talk, 'NPN: {(<N.*>+<P.*><N.*>+)+}','NPN')\n",
      "        featureVector.append(sum(len(njn_list), len(npn_list)))\n",
      "    return featureVector\n",
      "\n",
      "def num_first_person_pronoun_chunk(talk_sents):\n",
      "    featureVector = []\n",
      "    pro_verb = \"(<PR.*>|<N.*P>+)+<TO>?<MD>?<TO>?<VB.*>+\"\n",
      "    VB_grammar = \"PROVB: {\" + pro_verb + \"}\"\n",
      "    for talk in talk_sents:\n",
      "        pvb_list = extract_tree(talk,VB_grammar, \"PROVB\")\n",
      "        featureVector.append(len(pvb_list))\n",
      "    return featureVector    \n",
      "\n",
      "def num_words(talk_sents):\n",
      "    featureVector = []\n",
      "    for talk in talk_sents:\n",
      "        word_list = [word for sents in talk for word in sents]\n",
      "        num_words = len(word_list)        \n",
      "        featureVector.append(num_words)\n",
      "    return featureVector\n",
      "\n",
      "def avg_word_length(talk_sents):\n",
      "    featureVector = []\n",
      "    for talk in talk_sents:\n",
      "        word_list = [word for sents in talk for word in sents]\n",
      "        num_words = len(word_list)    \n",
      "        total_len = sum([len(sent) for sent in talk])\n",
      "        featureVector.append(total_len / num_words)\n",
      "    return featureVector\n",
      "\n",
      "def num_unique_words(talk_sents):\n",
      "    featureVector = []\n",
      "    for talk in talk_sents:\n",
      "        word_list = [word for sents in talk for word in sents]\n",
      "        num_unique = len(list(set(word_list)))\n",
      "        featureVector.append(num_unique)\n",
      "    return featureVector\n",
      "\n",
      "def num_unique_big_words(talk_sents):\n",
      "    featureVector = []\n",
      "    for talk in talk_sents:\n",
      "        word_list = [word for sents in talk for word in sents]\n",
      "        unique_big = len(list(set([word for word in word_list if len(word) > 10])))\n",
      "        featureVector.append(unique_big)\n",
      "    return featureVector\n",
      "\n",
      "def num_neg_words(talk_sents):\n",
      "    featureVector = []\n",
      "    for talk in talk_sents:\n",
      "        word_list = [word for sents in talk for word in sents]\n",
      "        num_neg = len([word for word in word_list if word in NEGATION_LIST])\n",
      "        featureVector.append(num_neg)\n",
      "    return featureVector\n",
      "\n",
      "def num_certain_words(talk_sents):\n",
      "    featureVector = []\n",
      "    for talk in talk_sents:\n",
      "        word_list = [word for sents in talk for word in sents]\n",
      "        num_certain = len([word for word in word_list if word in CERTAINTY_LIST])\n",
      "        featureVector.append(num_certain)\n",
      "    return featureVector\n",
      "\n",
      "def num_hedge_words(talk_sents):\n",
      "    featureVector = []\n",
      "    for talk in talk_sents:\n",
      "        word_list = [word for sents in talk for word in sents]\n",
      "        num_hedge = len([word for word in word_list if word in HEDGE_LIST])\n",
      "        featureVector.append(num_hedge)\n",
      "    return featureVector\n",
      "\n",
      "def num_sents(talk_sents):\n",
      "    featureVector = []\n",
      "    for talk in talk_sents:\n",
      "        featureVector.append(len(talk))\n",
      "    return featureVector\n",
      "\n",
      "def avg_words_sent(talk_sents):\n",
      "    featureVector = []\n",
      "    for talk in talk_sents:\n",
      "        word_list = [word for sents in talk for word in sents]\n",
      "        avg = len(word_list) / len(talk)\n",
      "        featureVector.append(avg)\n",
      "    return featureVector\n",
      "\n",
      "def num_paras(talk_paras):\n",
      "    featureVector = []\n",
      "    for talk in talk_paras:\n",
      "        featureVector.append(len(talk))\n",
      "    return featureVector\n",
      "\n",
      "def avg_words_para(talk_paras):\n",
      "    featureVector = []\n",
      "    for talk in talk_paras:\n",
      "        word_list = [word for paras in talk for sent in paras for word in sent]\n",
      "        avg = len(word_list) / len(talk)\n",
      "        featureVector.append(avg)\n",
      "    return featureVector\n",
      "\n",
      "def count_pos(tagged_words, pos_tag):\n",
      "    \"\"\"Counts number of occurrences of a particular POS in each talk\"\"\"\n",
      "    featureVector = []\n",
      "    for talk in tagged_words:\n",
      "        count = 0\n",
      "        for word , tag in talk:\n",
      "            if pos_tag in tag:\n",
      "                count += 1\n",
      "        featureVector.append(count)\n",
      "    return featureVector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def confusing_matrix():\n",
      "    header = [\"question_count\",\n",
      "               \"exclamation_count\",\n",
      "               \"semicolon_count\",\n",
      "               #\"num_techterms\", commented, needs to be removed later\n",
      "               #\"personal_pronoun\",\n",
      "               #\"num_words\",\n",
      "               \"avg_word_length\",\n",
      "               \"num_unique_words\",\n",
      "               \"num_unique_big_words\",\n",
      "               \"num_neg_words\",\n",
      "               \"num_certain_words\",\n",
      "               \"num_hedge_words\",\n",
      "               \"num_sents\",\n",
      "               \"avg_words_sent\",\n",
      "               \"num_paras\",\n",
      "               \"avg_words_para\",\n",
      "               \"count_adjectives\",\n",
      "               \"count_verbs\",\n",
      "               \"count_conjunction\",\n",
      "               \"count_verbs\"\n",
      "               ]\n",
      "    feature_list = []\n",
      "    \n",
      "    feature_list.append(min_max_normalize(punctuation_count(tagged_sents, \"?\")))\n",
      "    feature_list.append(min_max_normalize(punctuation_count(tagged_sents, \"!\")))\n",
      "    feature_list.append(min_max_normalize(punctuation_count(tagged_sents, \";\")))\n",
      "    #feature_list.append(min_max_normalize(num_techterms(tagged_sents))) #Commented, needs to be removed\n",
      "    #feature_list.append(min_max_normalize(num_first_person_pronoun_chunk(tagged_sents)))\n",
      "    #feature_list.append(min_max_normalize(num_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(avg_word_length(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_unique_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_unique_big_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_neg_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_certain_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_hedge_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_sents(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(avg_words_sent(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_paras(tagged_paras)))\n",
      "    feature_list.append(min_max_normalize(avg_words_para(tagged_paras)))\n",
      "    feature_list.append(min_max_normalize(count_pos(tagged_words, \"JJ\")))\n",
      "    feature_list.append(min_max_normalize(count_pos(tagged_words, \"VB\")))\n",
      "    feature_list.append(min_max_normalize(map(lambda x, y: x + y, count_pos(tagged_words, \"CC\"), count_pos(tagged_words, \"IN\"))))\n",
      "    feature_list.append(min_max_normalize(count_pos(tagged_words, \"VB\")))\n",
      "    df = pandas.DataFrame(feature_list)\n",
      "    df.index = header\n",
      "    df = df.transpose()\n",
      "    df['Label'] = map(int, confusing_y)\n",
      "    return df\n",
      "    \n",
      "#def funny_matrix():\n",
      "\n",
      "def informative_matrix():\n",
      "    header = [\"question_count\",\n",
      "               \"exclamation_count\",\n",
      "               \"semicolon_count\",\n",
      "               \"num_techterms\",\n",
      "               \"personal_pronoun\",\n",
      "               \"num_words\",\n",
      "               \"avg_word_length\",\n",
      "               \"num_unique_words\",\n",
      "               \"num_unique_big_words\",\n",
      "               \"num_neg_words\",\n",
      "               \"num_certain_words\",\n",
      "               \"num_hedge_words\",\n",
      "               \"num_sents\",\n",
      "               \"avg_words_sent\",\n",
      "               \"num_paras\",\n",
      "               \"avg_words_para\",\n",
      "               \"count_adjectives\",\n",
      "               \"count_verbs\",\n",
      "               \"count_conjunction\",\n",
      "               \"count_verbs\"\n",
      "               ]\n",
      "    feature_list = []\n",
      "    \n",
      "    feature_list.append(min_max_normalize(punctuation_count(tagged_sents, \"?\")))\n",
      "    feature_list.append(min_max_normalize(punctuation_count(tagged_sents, \"!\")))\n",
      "    feature_list.append(min_max_normalize(punctuation_count(tagged_sents, \";\")))\n",
      "    feature_list.append(min_max_normalize(num_techterms(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_first_person_pronoun_chunk(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(avg_word_length(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_unique_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_unique_big_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_neg_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_certain_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_hedge_words(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_sents(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(avg_words_sent(tagged_sents)))\n",
      "    feature_list.append(min_max_normalize(num_paras(tagged_paras)))\n",
      "    feature_list.append(min_max_normalize(avg_words_para(tagged_paras)))\n",
      "    feature_list.append(min_max_normalize(count_pos(tagged_words, \"JJ\")))\n",
      "    feature_list.append(min_max_normalize(count_pos(tagged_words, \"VB\")))\n",
      "    feature_list.append(min_max_normalize(map(lambda x, y: x + y, count_pos(tagged_words, \"CC\"), count_pos(tagged_words, \"IN\"))))\n",
      "    feature_list.append(min_max_normalize(count_pos(tagged_words, \"VB\")))\n",
      "    df = pandas.DataFrame(feature_list)\n",
      "    df.index = header\n",
      "    df = df.transpose()\n",
      "    df['Label'] = map(int, confusing_y)\n",
      "    return feature_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Split Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_feature_sets(data_frame, split=[.7,.2,.1]):\n",
      "    trainlen = int(split[0] * len(data_frame))\n",
      "    devlen = int(split[1] * len(data_frame))\n",
      "    return data_frame[:trainlen], data_frame[trainlen:trainlen+devlen], data_frame[trainlen:trainlen+devlen:]\n",
      "\n",
      "df_confusing = confusing_matrix()\n",
      "\n",
      "train_set_con, dev_set_con, test_set_con = create_feature_sets(df_confusing)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Train Test Predict"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create linear regression object\n",
      "regr = linear_model.LinearRegression()\n",
      "\n",
      "X_train = train_set_con.iloc[:,:-1]\n",
      "Y_train = train_set_con.iloc[:,-1]\n",
      "X_dev = dev_set_con.iloc[:,:-1]\n",
      "Y_dev = dev_set_con.iloc[:,-1]\n",
      "X_test =test_set_con.iloc[:,:-1]\n",
      "Y_test = test_set_con.iloc[:,-1]\n",
      "\n",
      "# Train the model using the training sets\n",
      "regr.fit(X_train, Y_train)\n",
      "\n",
      "# The coefficients\n",
      "print('Coefficients: \\n', regr.coef_)\n",
      "\n",
      "# The mean square error\n",
      "print(\"Residual sum of squares: %.2f\"\n",
      "      % np.mean((regr.predict(X_dev) - Y_dev) ** 2))\n",
      "\n",
      "# Explained variance score: 1 is perfect prediction\n",
      "print('Variance score: %.2f' % regr.score(X_dev, Y_dev))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Coefficients: \\n', array([  9.09210912e-03,   2.32664104e-03,  -8.34122142e-04,\n",
        "         1.34793555e-17,  -9.10747121e-04,   1.79271099e-17,\n",
        "         1.99204439e-18,  -1.40471716e-18,  -4.30562441e-18,\n",
        "        -2.99578369e-03,  -1.38607624e-02,   2.13393483e-02,\n",
        "         6.63343980e-03,   4.96332646e-03,   2.36654832e-04,\n",
        "        -1.72272675e-03,   2.36654832e-04]))\n",
        "Residual sum of squares: 10.78\n",
        "Variance score: -5.62\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Predict\n",
      "predicted_dev = regr.predict(dev_set_con.iloc[:,:-1])\n",
      "predicted_test = regr.predict(test_set_con.iloc[:,:-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Best possible score is 1.0, lower values are not ideal. Should we normalize the labels (Y values) as well?\n",
      "metrics.r2_score(Y_dev, predicted_dev), metrics.r2_score(Y_test, predicted_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "(-5.6245031574103201, -5.6245031574103201)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#We can use Lasso regression which itertively tries to find the most important predictor from a host of predictors."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Plots"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Trying to create a residual plot, need to figure out another way\n",
      "predicted_test = regr.predict(test_set_con.iloc[:,:-1])\n",
      "predicted_dev = regr.predict(dev_set_con.iloc[:,:-1])\n",
      "plt.scatter(predicted_test, predicted_test- test_set_con.iloc[:,-1], c='g')\n",
      "plt.scatter(predicted_dev, predicted_dev- dev_set_con.iloc[:,-1], c='b', alpha=0.5)\n",
      "#plt.plot([0.4,2],[0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "<matplotlib.collections.PathCollection at 0x27221828>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x24a37588>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Discourse"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tt = nltk.tokenize.texttiling.TextTilingTokenizer()\n",
      "bounds_list = list()\n",
      "\n",
      "for talk in tagged_paras:\n",
      "    para_list = list()\n",
      "    w_count = 0\n",
      "    for para in talk:\n",
      "        sent_list = list()        \n",
      "        for sent in para:\n",
      "            sent_list.append(' '.join([word+\"/\"+tag for word,tag in sent if word not in stopwords.words('english')]))\n",
      "            w_count += len(sent)\n",
      "        para_list.append(' '.join(sent_list))\n",
      "    if len(para_list) < 2:\n",
      "        bounds_list.append((len(para_list),0, w_count))\n",
      "        continue\n",
      "    \n",
      "    talk_text = '\\n\\n\\t'.join(para_list)\n",
      "    b_text = tt.tokenize(talk_text)\n",
      "    print len(b_text)\n",
      "    bounds_list.append((len(para_list), len(b_text), w_count))\n",
      "# print b_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "23"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "24"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "22"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "29"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# [p/float(b) for p,b,w in bounds_list if b != 0]\n",
      "disc_header = [\n",
      "#                 'num_topics',\n",
      "                'avg_topic_len',\n",
      "#                 'num_paras'\n",
      "               ]\n",
      "\n",
      "def num_paras(b_list):\n",
      "    feature_list = [p for p,b,w in b_list]\n",
      "    return feature_list\n",
      "\n",
      "def num_topics(b_list):\n",
      "    feature_list = [b for p,b,w in b_list]\n",
      "    return feature_list\n",
      "\n",
      "def avg_topic_len(b_list):\n",
      "    ret_list = list()\n",
      "    for p,b,w in b_list:\n",
      "        if b == 0:\n",
      "            ret_list.append(p)\n",
      "        else:\n",
      "            ret_list.append(p/float(b))\n",
      "    return ret_list\n",
      "\n",
      "# def create_discourse_features():\n",
      "disc_f_list = list()\n",
      "# disc_f_list.append(num_topics(bounds_list))\n",
      "disc_f_list.append(avg_topic_len(bounds_list))\n",
      "# disc_f_list.append(num_paras(bounds_list))\n",
      "disc_df = pandas.DataFrame(disc_f_list)\n",
      "disc_df.index = disc_header\n",
      "disc_df = disc_df.transpose()\n",
      "disc_df['Label'] = map(int, confusing_y)\n",
      "\n",
      "train_set_con_d, dev_set_con_d, test_set_con_d = create_feature_sets(disc_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regr_d = linear_model.LinearRegression()\n",
      "\n",
      "X_train_d = train_set_con_d.iloc[:,:-1]\n",
      "Y_train_d = train_set_con_d.iloc[:,-1]\n",
      "X_dev_d = dev_set_con_d.iloc[:,:-1]\n",
      "Y_dev_d = dev_set_con_d.iloc[:,-1]\n",
      "X_test_d =test_set_con_d.iloc[:,:-1]\n",
      "Y_test_d = test_set_con_d.iloc[:,-1]\n",
      "\n",
      "# Train the model using the training sets\n",
      "regr_d.fit(X_train_d, Y_train_d)\n",
      "\n",
      "# The coefficients\n",
      "print('Coefficients: \\n', regr_d.coef_)\n",
      "\n",
      "# The mean square error\n",
      "print(\"Residual sum of squares: %.2f\"\n",
      "      % np.mean((regr_d.predict(X_dev_d) - Y_dev_d) ** 2))\n",
      "\n",
      "# Explained variance score: 1 is perfect prediction\n",
      "print('Variance score: %.2f' % regr_d.score(X_dev_d, Y_dev_d))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Coefficients: \\n', array([ 0.09330557]))\n",
        "Residual sum of squares: 1.48\n",
        "Variance score: 0.09\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Predict\n",
      "predicted_dev_d = regr_d.predict(dev_set_con_d.iloc[:,:-1])\n",
      "predicted_test_d = regr_d.predict(test_set_con_d.iloc[:,:-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.r2_score(Y_dev_d, predicted_dev_d), metrics.r2_score(Y_test_d, predicted_test_d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "(0.090236207252047729, 0.090236207252047729)"
       ]
      }
     ],
     "prompt_number": 54
    }
   ],
   "metadata": {}
  }
 ]
}