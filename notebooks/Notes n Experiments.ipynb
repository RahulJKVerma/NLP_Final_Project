{
 "metadata": {
  "name": "",
  "signature": "sha256:4b9ab1cc08fad2eef1fa3a9af90a00da4ecffa46d6bfba90e1186400520c1e01"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Notes\n",
      "1. Get frequent nouns n grams\n",
      "2. Get frequent verb n grams\n",
      "3. Variety in the talk\n",
      "    1. Number of slides - Check for references like (this slide/this video).\n",
      "    2. Laughter \n",
      "    3. More goes here.. \n",
      "\n",
      "## Questions\n",
      "1. Did we lose the paragraph breaks? - Text tiling needs this\n",
      "\n",
      "## Todo\n",
      "1. Would be great to have a method in ted class to extract the metadata."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Classification features\n",
      "1. Punctuations.\n",
      "    1. '?' - thought provoking/call to action\n",
      "    2. '!' - engage audience through expression\n",
      "    3. ';' - could be negative. meaning long sentences\n",
      "2. Collocations:\n",
      "    1. Bigrams or collocated nouns/verbs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagged_sents = pickle.load(open('../Corpus/tagged_sents_talks.p', 'rb'))\n",
      "tagged_words = pickle.load(open('../Corpus/tagged_words_talks.p', 'rb'))\n",
      "sents = pickle.load(open('../Corpus/sents_talks.p', 'rb'))\n",
      "words = pickle.load(open('../Corpus/words_talks.p', 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fd_w = nltk.FreqDist(words[0])\n",
      "fd_w.items()[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[(',', 234),\n",
        " ('.', 215),\n",
        " ('the', 152),\n",
        " ('to', 81),\n",
        " ('you', 77),\n",
        " ('a', 74),\n",
        " ('of', 73),\n",
        " ('and', 68),\n",
        " ('I', 64),\n",
        " ('``', 61),\n",
        " ('in', 53),\n",
        " ('is', 48),\n",
        " (\"'s\", 47),\n",
        " ('we', 47),\n",
        " ('it', 46),\n",
        " ('that', 46),\n",
        " ('was', 46),\n",
        " (\"n't\", 43),\n",
        " ('And', 42),\n",
        " ('?', 38)]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tt = nltk.tokenize.texttiling.TextTilingTokenizer()\n",
      "text = ' '.join([' '.join(words) for words in sents[0]])\n",
      "print type(text)\n",
      "# s,ss,d,b = tt.tokenize(text)\n",
      "# misses paragraph breaks..!!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'str'>\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import pylab\n",
      "# pylab.xlabel(\"Sentence Gap index\")\n",
      "# pylab.ylabel(\"Gap Scores\")\n",
      "# pylab.plot(range(len(s)), s, label=\"Gap Scores\")\n",
      "# pylab.plot(range(len(ss)), ss, label=\"Smoothed Gap scores\")\n",
      "# pylab.plot(range(len(d)), d, label=\"Depth scores\")\n",
      "# pylab.stem(range(len(b)),b)\n",
      "# pylab.legend()\n",
      "# pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import wordnet as wn\n",
      "import re\n",
      "w_mphy = [wn.morphy(w,wn.NOUN) for w,t in tagged_words[0] if re.match('N*',t)]\n",
      "fd_wm = nltk.FreqDist(w_mphy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fd_wm.items()[:10]\n",
      "# tagged_words[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "[(None, 2648),\n",
        " ('a', 74),\n",
        " ('in', 53),\n",
        " ('it', 47),\n",
        " ('wa', 46),\n",
        " ('think', 28),\n",
        " ('have', 27),\n",
        " ('education', 22),\n",
        " ('are', 20),\n",
        " ('at', 20)]"
       ]
      }
     ],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}